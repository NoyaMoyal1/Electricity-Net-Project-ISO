ISO-RLZoo-v0:
  env_wrapper:
    - gymnasium.wrappers.RescaleAction:
        min_action: -1.0
        max_action: 1.0
  
  normalize: true

  n_envs: 4
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  n_steps: 1024
  batch_size: 128
  gae_lambda: 0.95
  gamma: 0.99
  n_epochs: 10
  ent_coef: 0.8
  learning_rate: !!float 1e-3
  clip_range: 0.2
  max_grad_norm: 2.0
  vf_coef: 0.5
  
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=True,
                       activation_fn=nn.Tanh,
                        net_arch=dict(shared=[64, 64], pi=[128, 64], vf=[128, 64]))"
    
  # Use our direct callback class
  callback: plot_callback.PlotCallback
